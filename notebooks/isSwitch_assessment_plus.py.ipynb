{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start coding here\n",
    "i_primary = snakemake.input.primary_aln\n",
    "i_ssdis = snakemake.input.ssdis_csv\n",
    "o_dataset_csv = snakemake.output.isSwitchPlus_dataset\n",
    "o_full_csv = snakemake.output.isSwitchPlus_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "\n",
    "from Bio import AlignIO\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "LETTERS = [\n",
    "    \"X\",# = residues that exist in the originally studied molecule \n",
    "        # (the SEQRES records of the PDB file) \n",
    "        # but not in the observed structure (the coordinate records of the PDB file)\n",
    "    \"H\",# = alpha helix\n",
    "    \"B\",# = residue in isolated beta-bridge\n",
    "    \"E\",# = extended strand, participates in beta ladder\n",
    "    \"G\",# = 3-helix (3/10 helix)\n",
    "    \"I\",# = 5 helix (pi helix)\n",
    "    \"T\",# = hydrogen bonded turn\n",
    "    \"S\",# = bend\n",
    "    \"L\", # CUSTOM = stands for a loop or other irregular structure\n",
    "    \"-\", # indel from alignment\n",
    "    #\"?\" # missing in SS_DIS, not needed as these are removed early\n",
    "    ]\n",
    "    \n",
    "DEFINED_SECONDARY_STRUCTURE = [\"H\",\"B\",\"E\",\"G\",\"I\",\"T\",\"S\",\"L\"]\n",
    "    \n",
    "\n",
    "def _create_ssdis_analysis(ssdis):\n",
    "    \"\"\" appends analysis columns based on input dataframe \n",
    "    \n",
    "    returns:\n",
    "        dataframe with secondary structure data based analysis\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    \n",
    "    # remove all alignments with ? indicating SS_DIS did not contain them\n",
    "    # removes any column (e.g. an aligned sequence) where the ss_dis data was missing\n",
    "    #print((ssdis == '?').any())\n",
    "    ssdis = ssdis.loc[:, ~(ssdis == '?').any()]\n",
    "    \n",
    "    for i, row in enumerate(ssdis.iterrows()):\n",
    "        counts = Counter(row[1])\n",
    "        cluster_size = len(row[1])\n",
    "        # if cluster size drops below at least 2 after removing missing ss_dis columns\n",
    "        # raise ValueError\n",
    "        # if cluster_size < 2:\n",
    "        #    raise ValueError(\"One or Zero sequences remaining after removing missing ss_dis columns\")\n",
    "        \n",
    "        # generate counts and proportions for each secondary structure letter\n",
    "        for letter in LETTERS:\n",
    "            ssdis.at[i, f\"{letter}_count\"] = counts[letter]\n",
    "            # size of the characters MINUS indel characters at the position\n",
    "            # this will give proportion of residues present, ignoring alignment indels\n",
    "            # set proportios to zero in first case \n",
    "            # (where all positions are indels, this occurs when an alignment like '-,-,?' occurs\n",
    "            # because ? columns are removed)\n",
    "            if cluster_size - counts[\"-\"] == 0:\n",
    "                ssdis.at[i, f\"{letter}_proportion_of_present\"] = 0\n",
    "                ssdis.at[i, f\"-_proportion_of_present\"] = 1\n",
    "            else:\n",
    "                ssdis.at[i, f\"{letter}_proportion_of_present\"] = (counts[letter]/(cluster_size-counts[\"-\"])) \n",
    "        \n",
    "    ssdis[\"ClusterSize\"] = cluster_size\n",
    "    \n",
    "    ########################################\n",
    "    # START SWITCH ASSIGNMENT\n",
    "    # switch categories categorized here\n",
    "    # WARN: THE ORDER IS VERY IMPORTANT HERE AS LATER CATERGORIES SUPERSEDE EARLY ONES\n",
    "\n",
    "    # default value set\n",
    "    ssdis[f\"isSwitch\"] = \"SwitchObserved\"\n",
    "\n",
    "    # set to Missing Observations\n",
    "    ssdis.loc[ssdis[\"X_count\"] > 1, \"isSwitch\"] = \"NoSwitchObserved_WithUnobservedPositions\"\n",
    "\n",
    "\n",
    "    # 100% SINGLE DEFINED_SECONDARY_STRUCTURE\n",
    "    for letter in DEFINED_SECONDARY_STRUCTURE:\n",
    "        ssdis.loc[ssdis[f\"{letter}_proportion_of_present\"] == 1, \"isSwitch\"] = \"NoSwitchObserved\"\n",
    "    \n",
    "    \n",
    "    # END SWITCH ASSIGNMENT\n",
    "    ########################################\n",
    "        \n",
    "    return ssdis\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "def isSwitchPlus(primary_aln_path, ssdis_csv_path):\n",
    "    \"\"\" Combines primary sequence data and ssdis aligned data\n",
    "    \n",
    "    Outputs:\n",
    "        isSwitch\n",
    "        percentage breakdown in secondary structures\n",
    "        length of alignment (e.g. cluster size)\n",
    "    \n",
    "    \"\"\"\n",
    "    # import ssdis data and generate analysis columns\n",
    "    ssdis = _create_ssdis_analysis(pd.read_csv(ssdis_csv_path))\n",
    "    \n",
    "    # import primary sequence alignment and append to dataframe\n",
    "    aln = AlignIO.read(primary_aln_path, format=\"fasta\")\n",
    "    for seq in aln:\n",
    "        try:\n",
    "            ssdis[f\"{seq.id}_primary\"] = list(seq.seq)\n",
    "        except ValueError as e:\n",
    "            #print(seq.seq)\n",
    "            #display(ssdis)\n",
    "            raise e\n",
    "    \n",
    "    ssdis_datasets = {}\n",
    "    for seq in aln:\n",
    "        seq_primary = f\"{seq.id}_primary\"\n",
    "        save_these_columns = [seq_primary, \"ClusterSize\", \"isSwitch\"]\n",
    "        save_these_columns.extend([f\"{letter}_count\" for letter in LETTERS])\n",
    "        print(save_these_columns)\n",
    "        dataset_df = ssdis.filter(axis=\"columns\", items=save_these_columns)\n",
    "        # make column label generic for primary sequence\n",
    "        dataset_df = dataset_df.rename(axis=\"columns\",mapper={seq_primary:\"primary\"})\n",
    "        ssdis_datasets[seq.id] = dataset_df\n",
    "    \n",
    "    \n",
    "    return ssdis_datasets, ssdis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%timeit -n 1 -r 1\n",
    "\n",
    "import os\n",
    "\n",
    "\n",
    "dataset_dfs, full_df  = isSwitchPlus(primary_aln_path=i_primary, \n",
    "                                     ssdis_csv_path=i_ssdis)\n",
    "\n",
    "    \n",
    "# save results to both dataset compatible csv and full cluster csv format\n",
    "for seqID, df in dataset_dfs.items():\n",
    "    # format for each member of the cluster\n",
    "    # \n",
    "    o_dataset_path = os.path.join(os.path.dirname(o_dataset_csv)[:-2], # removing extra hash directory \n",
    "                                  seqID[0:2],  # hash\n",
    "                                  f\"{seqID}.csv\") #seqID\n",
    "    os.makedirs(os.path.dirname(o_dataset_path), exist_ok=True)\n",
    "    #print(o_dataset_path)\n",
    "    df.to_csv(o_dataset_path)\n",
    "full_df.to_csv(o_full_csv)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
